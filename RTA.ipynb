{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo List\n",
    "\n",
    "#### Minimum Requirements\n",
    "\n",
    "[x] Return top ticker names from a given time interval\n",
    "\n",
    "[x] Filter comments for tickers\n",
    "\n",
    "[X] Filter posts for tickers\n",
    "\n",
    "[x] Remove stop words\n",
    "\n",
    "#### Recommended\n",
    "\n",
    "[X] Separate API credentials to separate file\n",
    "\n",
    "[X] Bot detection\n",
    "\n",
    "[X] Have threshold for karma for posts\n",
    "\n",
    "[X] Have threshold for karma for comments\n",
    "\n",
    "[X] Have threshold for age of Redditor\n",
    "\n",
    "[X] Handle repeat tickers in the same post/comment instance\n",
    "\n",
    "[ ] Visualization of tickers name per day (stacked bar chart)\n",
    "\n",
    "[ ] Visualization of sectors\n",
    "\n",
    "[ ] Determine percent change of ticker frequency (requires Future To-Do #1)\n",
    "\n",
    "#### Future\n",
    "\n",
    "[ ] Write the data to a file so that we can build data over time\n",
    "\n",
    "[ ] Auto-rerun for live-stream of data\n",
    "\n",
    "    [ ] Live ticker dashboard\n",
    "\n",
    "    [ ] Live line graph for popular tickers\n",
    "\n",
    "    [ ] Correlation between current market performance and ticker mentions\n",
    "\n",
    "[ ] Sentimental analysis of tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Links\n",
    "\n",
    "https://praw.readthedocs.io/en/latest/code_overview/models/comment.html?highlight=comment\n",
    "https://api.pushshift.io/reddit/search/submission/?subreddit=learnpython&sort=desc&sort_type=created_utc&after=1523588521&before=1523934121&size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\programdata\\anaconda3\\lib\\site-packages (7.1.4)\n",
      "Requirement already satisfied: prawcore<2.0,>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from praw) (1.5.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from praw) (0.57.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from prawcore<2.0,>=1.5.0->praw) (2.24.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ken\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ken\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.5.0->praw) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ken\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import praw\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, OrderedDict\n",
    "import json\n",
    "\n",
    "# Get API credentials from local file\n",
    "file = open('config.json')\n",
    "config = json.load(file) \n",
    "\n",
    "# Initialize praw\n",
    "reddit = praw.Reddit(client_id = config['client_id'],\n",
    "                     client_secret = config['client_secret'],\n",
    "                     user_agent = config['user_agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "moKenFilter = {'rh','dd', 'ev', 'usd', 'lol', 'td', 'ceo', 'cto', 'coo', 'cfo', 'ipo',\n",
    "              'gild', 'buy', 'imo', 'usa', 'good', 'one', 'go', 'know', 'see', 'well', 'new',\n",
    "              'hold', 'want', 'need', 'next', 'post', 'play', 'sub', 'big', 'ive', 'term', 'real',\n",
    "              'man', 'ago', 'cash', 'nice', 'pump', 'edit', ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeDiff (unixTime, threshold):\n",
    "    '''\n",
    "    Calculate time difference between current time and input time.\n",
    "    \n",
    "    :return: True if time difference within threshold, False otherwise\n",
    "    :return type: bool\n",
    "    '''\n",
    "    now = datetime.utcnow()\n",
    "    timestamp = datetime.utcfromtimestamp(unixTime).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    timestamp = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    triangle = (now - timestamp).total_seconds() / 3600\n",
    "    if triangle <= (threshold):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debugPrint(body, tickersDictGood, tickersDictFair, tickersDictPoor):\n",
    "    '''\n",
    "    Debug printing function to print out ticker values\n",
    "    \n",
    "    :param input body: the message to be printed initially\n",
    "    :param type: str\n",
    "    \n",
    "    :param input tickersDictXXXX: the dataframe to print values from\n",
    "    :param type: dict\n",
    "    '''\n",
    "    print(body + str(sum(tickersDictGood.values()) + \n",
    "                               sum(tickersDictFair.values()) +\n",
    "                               sum(tickersDictPoor.values())\n",
    "          ))\n",
    "    print(\"Tickers from good accounts: \" + str(sum(tickersDictGood.values())))\n",
    "    print(\"Tickers from fair accounts: \" + str(sum(tickersDictFair.values())))\n",
    "    print(\"Tickers from poor accounts: \" + str(sum(tickersDictPoor.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract tickers from dataframe column\n",
    "def get_ticker_from_col(dictGood, dictFair, dictPoor, data_col, karma_col, age_col):\n",
    "    '''\n",
    "    Extract the ticker names that appear in a specific dataframe column\n",
    "    \n",
    "    :param input dictGood: ticker counts from users with old accs and high karma\n",
    "    :param type: dict\n",
    "    \n",
    "    :param input dictGood: ticker counts from either old acc OR high karma users\n",
    "    :param type: dict\n",
    "    \n",
    "    :param input dictGood: ticker counts from users with new acc and no karma (probably bots)\n",
    "    :param type: dict\n",
    "    \n",
    "    :param input df_col: dataframe column to be read\n",
    "    :param type: pd.DataFrame (single column only)\n",
    "    '''\n",
    "    # Filter comments for all tickers that show up\n",
    "    punct_table = str.maketrans(dict.fromkeys(string.punctuation)) # Holds all punctuation\n",
    "    for i in range(len(data_col)):\n",
    "        tickers = set()\n",
    "        for word in data_col.iloc[i].split():\n",
    "            word = word.translate(punct_table) # Remove punctuation \n",
    "            if word == \"\": # if word is empty\n",
    "                continue\n",
    "            elif len(word) > 5: # if word is clearly not a ticker\n",
    "                continue\n",
    "            elif word.lower() in stopwords.words('english') or word.lower() in moKenFilter:\n",
    "                continue\n",
    "            elif word.isnumeric():\n",
    "                continue\n",
    "            elif word in tickers: # if current comment already encountered this specific ticker\n",
    "                continue\n",
    "            elif word in dictGood: #handle if ticker starts with $\n",
    "                tickers.add(word)\n",
    "                if karma_col.iloc[i] and age_col.iloc[i]:\n",
    "                    dictGood[word] += 1\n",
    "                elif karma_col.iloc[i] or age_col.iloc[i]:\n",
    "                    dictFair[word] += 1\n",
    "                else:\n",
    "                    dictPoor[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateAuthorKarma(redditor, KARMA_THRESHOLD):\n",
    "    '''\n",
    "    Determine if redditor has more karma than some threshold\n",
    "    \n",
    "    :param input redditor: redditor to check age of\n",
    "    :param type: praw.redditor\n",
    "    \n",
    "    :param input KARMA_THRESHOLD: threshold to use for karma\n",
    "    :param type: int'''\n",
    "    if not redditor or not redditor.comment_karma or not redditor.link_karma:\n",
    "        return False\n",
    "    return redditor.comment_karma + redditor.link_karma > KARMA_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateAuthorAge(redditor, AGE_THRESHOLD):\n",
    "    '''\n",
    "    Determine if redditor is older than some threshold\n",
    "    \n",
    "    :param input redditor: redditor to check age of\n",
    "    :param type: praw.redditor\n",
    "    \n",
    "    :param input AGE_THRESHOLD: threshold to use for age\n",
    "    :param type: int'''\n",
    "    if not redditor or not redditor.created_utc: return False\n",
    "    \n",
    "    # replace with method \n",
    "    now = datetime.utcnow()\n",
    "    timestamp = datetime.utcfromtimestamp(redditor.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    timestamp = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    triangle = (now - timestamp).total_seconds() / 3600\n",
    "    return triangle >= AGE_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract top tickers from\n",
    "def extract_tickers(input_subreddit, threshold=168, limit=100, debug=False):\n",
    "    '''\n",
    "    Extract the most frequent tickers from a given subreddit for a desired timeframe\n",
    "    \n",
    "    :param input_subreddit: subreddit to be queried\n",
    "    :param type: str\n",
    "    \n",
    "    :param threshold: how far back (in hours) in the past to retrieve data from\n",
    "    :param type: int\n",
    "    :param default: 1 week = 7 days * 24 hours = 168 hours\n",
    "    \n",
    "    :param limit: set upper bound of number of posts to read\n",
    "    :param type: int\n",
    "    \n",
    "    :param debug: debug flag to print stuff\n",
    "    :param type: bool\n",
    "    \n",
    "    :return: sorted dictionaries for ticker appearances in a subreddit\n",
    "             distributed based on account legitimacy\n",
    "    :return type: dict\n",
    "    '''\n",
    "    start = datetime.utcnow()\n",
    "    if debug: print(\"Starting time: \", start.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    if debug: print(\"Running in debug mode with following params: \" + str(input_subreddit) + \", \" \n",
    "                                                                    + str(threshold) + \", \"\n",
    "                                                                    + str(limit))\n",
    "    # Thresholds for account reliability\n",
    "    AGE_THRESHOLD = 180 * 24 # number of days * hours in a day\n",
    "    KARMA_THRESHOLD = 250 # minimum karma\n",
    "    \n",
    "    subreddit = reddit.subreddit(input_subreddit)\n",
    "    \n",
    "    \n",
    "    # Gather all posts from subreddit that are within the threshold\n",
    "    posts = []\n",
    "    postsParsed = 0\n",
    "    for post in subreddit.new(limit=limit):\n",
    "        postsParsed += 1\n",
    "        if debug and(postsParsed % 100 == 0): print(\"Posts Parsed: \", postsParsed)\n",
    "        if timeDiff(post.created, threshold):\n",
    "            posts.append([post.title, post.author, validateAuthorKarma(post.author, KARMA_THRESHOLD), \n",
    "                          validateAuthorAge(post.author, AGE_THRESHOLD), post.score, \n",
    "                          post.id, post.subreddit, post.selftext, post.created])\n",
    "        else: continue\n",
    "    posts = pd.DataFrame(posts,columns=['title', 'author', 'authorKarmaValid', 'authorAgeValid', \n",
    "                                        'score', 'id', 'subreddit', 'body', 'created'])\n",
    "    \n",
    "    if debug: print(\"Number of posts found in timeframe provided: \" + str(len(posts)))\n",
    "        \n",
    "    # Gather all comments found in posts above\n",
    "    comments = []\n",
    "    index = 0;\n",
    "    for postId in posts['id']:\n",
    "        submission = reddit.submission(id=postId)\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        for comment in submission.comments.list():\n",
    "            index+=1\n",
    "            if debug and index% 1000 == 0:print(\"Comments parsed: \" + str(index))\n",
    "            if comment.author != 'AutoModerator' and type(comment.author) is praw.models.reddit.redditor.Redditor:\n",
    "                try:\n",
    "                    if comment.author.is_suspended: \n",
    "                        print(\"Suspended Author Name:\", comment.author)\n",
    "                        continue\n",
    "                except Exception:\n",
    "                    index = index #remove this later\n",
    "                \n",
    "                comments.append([comment.score, comment.author, \n",
    "                                 validateAuthorKarma(comment.author, KARMA_THRESHOLD),\n",
    "                                 validateAuthorAge(comment.author, AGE_THRESHOLD), \n",
    "                                 comment.body, comment.created,\n",
    "                                 str(datetime.utcfromtimestamp(comment.author.created_utc).strftime('%Y-%m-%d %H:%M:%S'))])\n",
    "    comments = pd.DataFrame(comments, columns=['score', 'author', 'authorKarmaValid', \n",
    "                                               'authorAgeValid', 'body','created', 'author_created'])\n",
    "    \n",
    "    if debug: print(\"Number of comments found in timeframe provided: \" + str(len(comments)))\n",
    "        \n",
    "    # Set up structure to hold ticker counts\n",
    "    tickers = pd.read_csv(\"tickers.csv\") \n",
    "    tickers = set(tickers['Symbol'])\n",
    "    tickersDictGood = dict() # Users that are legit (both old acc and decent karma)\n",
    "    tickersDictFair = dict() # Users that are lurkers or new (either old acc or high karma, not both)\n",
    "    tickersDictPoor = dict() # Users that are possibly bots (new acc and no karma)\n",
    "    for ticker in tickers:\n",
    "        tickersDictGood[ticker] = 0\n",
    "        tickersDictFair[ticker] = 0\n",
    "        tickersDictPoor[ticker] = 0\n",
    "    \n",
    "    # Extract tickers from comments\n",
    "    get_ticker_from_col(tickersDictGood, tickersDictFair, tickersDictPoor, \n",
    "                        comments['body'], comments['authorKarmaValid'], comments['authorAgeValid'])\n",
    "    if debug: debugPrint(\"Tickers from comments: \", tickersDictGood, tickersDictFair, tickersDictPoor)\n",
    "        \n",
    "    get_ticker_from_col(tickersDictGood, tickersDictFair, tickersDictPoor, \n",
    "                        posts['body'], posts['authorKarmaValid'], posts['authorAgeValid'])\n",
    "    if debug: debugPrint(\"Tickers from comments and posts: \", tickersDictGood, \n",
    "                         tickersDictFair, tickersDictPoor)\n",
    "        \n",
    "    get_ticker_from_col(tickersDictGood, tickersDictFair, tickersDictPoor, \n",
    "                        posts['title'], posts['authorKarmaValid'], posts['authorAgeValid'])\n",
    "    if debug: debugPrint(\"Tickers from comments, posts, and post titles: \", tickersDictGood, \n",
    "                         tickersDictFair, tickersDictPoor)\n",
    "    if debug: print(\"Time elapsed: \", (datetime.utcnow()-start).total_seconds()/60)\n",
    "        \n",
    "    return (dict(OrderedDict(sorted(tickersDictGood.items(), key = lambda t: t[1] ,reverse=True))), \n",
    "            dict(OrderedDict(sorted(tickersDictFair.items(), key = lambda t: t[1] ,reverse=True))), \n",
    "            dict(OrderedDict(sorted(tickersDictPoor.items(), key = lambda t: t[1] ,reverse=True))),\n",
    "            posts,\n",
    "            comments,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time:  2021-02-17 03:38:23\n",
      "Running in debug mode with following params: wallstreetbets, 168, 50\n",
      "Number of posts found in timeframe provided: 50\n",
      "Comments parsed: 1000\n",
      "Comments parsed: 2000\n",
      "Number of comments found in timeframe provided: 2114\n",
      "Tickers from comments: 190\n",
      "Tickers from good accounts: 163\n",
      "Tickers from fair accounts: 25\n",
      "Tickers from poor accounts: 2\n",
      "Tickers from comments and posts: 218\n",
      "Tickers from good accounts: 185\n",
      "Tickers from fair accounts: 31\n",
      "Tickers from poor accounts: 2\n",
      "Tickers from comments, posts, and post titles: 239\n",
      "Tickers from good accounts: 202\n",
      "Tickers from fair accounts: 33\n",
      "Tickers from poor accounts: 4\n",
      "Time elapsed:  5.849374249999999\n"
     ]
    }
   ],
   "source": [
    "good, fair, poor, comments = extract_tickers('wallstreetbets', threshold = 7*24, \n",
    "                                              limit = 50, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GME', 39),\n",
       " ('AMC', 10),\n",
       " ('RIOT', 9),\n",
       " ('BP', 6),\n",
       " ('YOLO', 6),\n",
       " ('MVIS', 6),\n",
       " ('DNN', 5),\n",
       " ('AMD', 5),\n",
       " ('EPS', 4),\n",
       " ('CAT', 4)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pennystocks_good.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GME', 4),\n",
       " ('AMD', 2),\n",
       " ('MO', 2),\n",
       " ('ARKW', 1),\n",
       " ('TEAM', 1),\n",
       " ('MPC', 1),\n",
       " ('BAK', 1),\n",
       " ('EPS', 1),\n",
       " ('DNN', 1),\n",
       " ('RIOT', 1)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pennystocks_fair.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AMD', 1),\n",
       " ('B', 1),\n",
       " ('YOLO', 1),\n",
       " ('GME', 1),\n",
       " ('GER', 0),\n",
       " ('CI', 0),\n",
       " ('AMED', 0),\n",
       " ('JPMF', 0),\n",
       " ('PBSM', 0),\n",
       " ('IEZ', 0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pennystocks_poor.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# returns a list of time difference of seconds if within threshold return delta, otherwise -1\n",
    "def dateDiff(listOfUnixTime, threshold):\n",
    "    dateDiffs = []\n",
    "    for item in listOfUnixTime:\n",
    "        dt = datetime.utcfromtimestamp(item).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        date_time_obj = datetime.strptime(dt, '%Y-%m-%d %H:%M:%S')\n",
    "        triangle = (ts - date_time_obj).seconds\n",
    "        if( triangle >= threshold ):\n",
    "            dateDiffs.append(-1)\n",
    "        else:\n",
    "            dateDiffs.append(triangle)\n",
    "    return dateDiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tickers = pd.read_csv(\"tickers.csv\") \n",
    "tickers = set(tickers['Symbol'])\n",
    "tickersDict = dict()\n",
    "for ticker in tickers:\n",
    "    tickersDict[ticker] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wsb_subreddit = reddit.subreddit('wallstreetbets')\n",
    "posts = []\n",
    "for post in wsb_subreddit.new(limit=100):\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, \n",
    "                  post.url, post.num_comments, post.selftext, post.created])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
    "dayInSeconds = 86400\n",
    "postThreshold = dayInSeconds\n",
    "posts['timeDiff'] = dateDiff(posts['created'], postThreshold)\n",
    "posts = posts[posts.timeDiff > -1]\n",
    "\n",
    "#set another threshold for post karma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comments = []\n",
    "for postId in posts['id']:\n",
    "    submission = reddit.submission(id=postId)\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    for comment in submission.comments.list():\n",
    "        if comment.author != 'AutoModerator':\n",
    "            comments.append([ comment.score, comment.author, comment.body, comment.created])\n",
    "\n",
    "commentsDF = pd.DataFrame(comments, columns=['score','author','body','created'])\n",
    "commentsDF['timeDiff'] = dateDiff(commentsDF['created'], postThreshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# letTheBodiesHitTheFloor\n",
    "punct_table = str.maketrans(dict.fromkeys(string.punctuation)) # Holds all punctuation\n",
    "for body in commentsDF['body']:\n",
    "    for word in body.split():\n",
    "        word = word.translate(punct_table) # Remove punctuation \n",
    "        if word == \"\": # if word is empty\n",
    "            continue\n",
    "        elif len(word) > 5: # if word is clearly not a ticker\n",
    "            continue\n",
    "        elif word.lower() in stopwords.words('english') or word.lower() in moKenFilter:\n",
    "            continue\n",
    "        elif word.isnumeric():\n",
    "            continue\n",
    "        elif word in tickersDict: #handle if ticker starts with $\n",
    "            tickersDict[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tickersSorted = dict(OrderedDict(sorted(tickersDict.items(), key = lambda t: t[1] ,reverse=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
